\chapter{Related Work}\label{cha:related-work}
In this chapter, we will discuss some of the related work in the area of entity recognition with a focus on bibliographic information extraction from research papers.
We will also consider an approach on entity recognition that uses unlabeled data during the learning process.

\bigskip

\citet{giles1998citeseer} propose one of the first autonomous citation indexing systems called \emph{CiteSeer}.
The system uses heuristics following an ``invariants first'' philosophy for detecting the different fields in reference strings~\citep{giles1998citeseer}.
Thereby, fields that appeared in similar positions for all reference strings are parsed first.
Additionally, databases that contain for example author or journal names are used.
In an evaluation of \num{5093} documents related to the topic of ``neural networks'', $80.2\%$ of the titles, $82.1\%$ of the authors, and $44.2\%$ of the page numbers were extracted correctly from the retrieved references~\cite{giles1998citeseer}.

\citet{peng2004accurate}, \citet{councill2008parscit}, as well as \citet{groza2012reference} rely on \glspl{crf}~\citep{lafferty2001conditional} for extracting bibliographic information from research papers.
The three approaches followed the same steps:
After extracting and segmenting the reference strings, they are split into tokens and each token gets assigned a number of features.
Example for such features are the position in the line, whether or not the token starts with a capitalized letter, contains a dot, or only contains digits.
In addition, external lexicons are used in order to determine features like (author) surnames, places, and months.
The \glspl{crf} are learned on fully labeled data sets containing between 200 and 830 reference strings.
The labels represent the different fields in a reference string such as the authors, title, date, and publisher.
The resulting \gls{crf} model is then used for labeling unseen testing data and the performance is evaluated using the metrics \gls{precision}, \gls{recall}, and \gls{f1 score} (see \Cref{cha:evaluation}).
\citet{groza2012reference} compares the three mentioned studies by applying them on the \textit{Cora} dataset\footnote{\url{https://people.cs.umass.edu/~mccallum/data.html} (accessed Aug.~6,~2016)} which resulted from the Cora portal for research papers~\citep{mccallum2000automating}.
The approach by \citet{groza2012reference} outperforms the two other approached and has a \glspl{f1 score} higher than $93\%$ for all considered labels~\citep{groza2012reference}.
For the author labels, they achieve a \gls{f1 score} of $99.3\%$ for the Cora dataset.

\bigskip

Instead of relying on fully labeled data, \citet{lu2013web} use the approach of \gls{distant supervision} in combination with \glspl{ge criterion} to learn \gls{crf} models.
Their goal is to extract named entities such as organizations, persons, or places from web pages~\citep{lu2013web}.
For this, they use \textit{DBpedia}\footnote{\url{http://wiki.dbpedia.org/} (accessed Aug.~6,~2016)} as a knowledge base for the different entity types for the automated labeling of semi-structured HTML elements.
After additionally applying a collective detection model, an evaluation on \num{16755} manually labeled named entities shows a \gls{f1 score} of $72.56\%$ with a \gls{precision} of $70.46\%$ and \gls{recall} of $74.79\%$~\citep{lu2013web}.

\bigskip

To summarize, several aspects of the bibliographic information extraction from research papers can be achieved with a considerably good performance.
Especially the segmentation of a given reference string into its elements by using \glspl{crf} \citep{peng2004accurate,councill2008parscit,groza2012reference} shows very promising results.
Yet, all current approaches have in common that they rely on manually labeled data sets for training their models.
Manually labeled data sets are expensive and thereby usually only exist in smaller quantities.
In our particular use case of extracting references from German social science research papers, no such data set is currently available.
\citet{lu2013web} show a promising approach that allows a distantly supervised learning of \glspl{crf} using \glspl{ge criterion}.

In the following, we will first discuss \glspl{crf} as well as \gls{distant supervision} in general.
We will then consider our author extraction problem and how a distantly supervised approach can be applied to it.

