\chapter{Related Work}\label{cha:related-work}
In this chapter we will give an overview of the related work in the area of information extraction from research papers. This will lead us to the statistical modeling method of \glspl{crf}. We will also survey distant supervision\todo{add gls} as a method for generating training data of labeled reference strings. We will also discuss relevant literature for evaluating reference string extraction.\\

There has been a large body of research on information extraction from research papers and in the following we discuss a number of examples for such research.

\citet{powley2007evidence} address both citation extraction and citation-reference matching in research papers. For the citation extraction, they achieve a very high precision (0.9988) and recall (0.9678) by identifying pairs of year and author surnames in the text. The citation-reference matching was done in an integrated fashion. A plain text representation of the reference section was segmented into reference strings by matching the author and year information form the extracted citation data. This approach again resulted in a very high precision and recall for both the reference segmentation and citation-reference matching \citep{powley2007evidence}.

In order to simplify the creation of personal digital libraries, \citet{marinai2009metadata} proposes a software that combines \gls{pdf} parsing, low level document image processing, and layout analysis. First, text blocks of the research paper are segmented and annotated with layout information such as the position on the page and the width and height of the text block. Then, a \gls{mlp} classifier is applied on the annotated text blocks in order to extract the title and authors of the research paper. Based on this pair of title and authors, additional information about the paper is extracted from the DBLP\footnote{\url{http://dblp.uni-trier.de/}} computer science bibliography. Evaluated on 80 papers, the approach of learning from layout information resulted in successfully extracting 95\% of the titles and, by integrating information from DBLP, 73.58\% of the authors.

\citet{dejean2005structuring} aim to extract information about a research papers' structure from its \gls{toc}. The approach is based on general properties of the \gls{toc} such as the contiguity, textual similarity, and ordering of the references in relation to sections in the paper. The evaluation showed very high precision an recall for both the \gls{toc} and link extraction \citep{dejean2005structuring}.

For extracting bibliographic attributes from research papers that are only available as images, \citet{takasu2003bibliographic} uses optical character recognition combined with a variation of \glspl{hmm}. The evaluation was based on 1,575 references obtained from Japanese journal papers and the reported accuracy was above 90\% for all extracted bibliographic attributes except the volume and volume number.

\cite{peng2004accurate}, \cite{councill2008parscit}, and \cite{groza2012reference} also extract bibliographic information from research papers but rely on \glspl{crf} instead of \glspl{hmm}. All three papers share a similar approach: After extracting and segmenting the reference strings, \dots



\itodo{On entity recognition in research papers (different kinds of information like tables\dots as well as different methods)}
\itodo{Usage of CRFs for entity recognition}
\itodo{Distant supervision for building training set}
\itodo{Evaluation of entity recognition}

\itodo{Tooles for PDF to plain text}
\citet{marinai2009metadata} uses Apache PDFBox\footnote{\url{https://pdfbox.apache.org/}}, a Java \gls{pdf} library for segmenting research papers into text blocks in order to perform layout analysis.
