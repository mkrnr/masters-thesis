\chapter{Related Work}\label{cha:related-work}
In this chapter we will give an overview of the related work in the area of information extraction from research papers.
This will lead us to the statistical modeling method of \glspl{crf}.
We will also survey distant supervision\todo{add gls} as a method for generating training data of labeled reference strings.
We will also discuss relevant literature for evaluating reference string extraction.\\

There has been a large body of research on information extraction from research papers and in the following we discuss a number of examples for such research.

In order to simplify the creation of personal digital libraries, \citet{marinai2009metadata} proposes a software that combines \gls{pdf} parsing, low level document image processing, and layout analysis.
First, text blocks of the research paper are segmented and annotated with layout information such as the position on the page and the width and height of the text block.
Then, a \gls{mlp} classifier is applied on the annotated text blocks in order to extract the title and authors of the research paper.
Based on this pair of title and authors, additional information about the paper is extracted from the DBLP\footnote{\url{http://dblp.uni-trier.de/}} computer science bibliography.
Evaluated on 80 papers, the approach of learning from layout information resulted in successfully extracting 95\% of the titles and, by integrating information from DBLP, 73.58\% of the authors.

\citet{dejean2005structuring} aim to extract information about a research papers' structure from its \gls{toc}.
The approach is based on general properties of the \gls{toc} such as the contiguity, textual similarity, and ordering of the references in relation to sections in the paper.
The evaluation showed very high precision an recall for both the \gls{toc} and link extraction \citep{dejean2005structuring}.

\citet{powley2007evidence} address both citation extraction and citation-reference matching in research papers.
For the citation extraction, they achieved a very high precision (0.9988) and recall (0.9678) by identifying pairs of year and author surnames in the text.
The citation-reference matching was done in an integrated fashion.
A plain text representation of the reference section was segmented into reference strings by matching the author and year information form the extracted citation data.
This approach again resulted in a very high precision and recall for both the reference segmentation and citation-reference matching \citep{powley2007evidence}.

For extracting bibliographic attributes from research papers that are only available as images, \citet{takasu2003bibliographic} uses optical character recognition combined with a variation of \glspl{hmm}.
The evaluation was based on 1,575 references obtained from Japanese journal papers and the reported accuracy was above 90\% for all extracted bibliographic attributes except the volume and volume number.

Instead of using \glspl{hmm}, \citet{peng2004accurate}, \citet{councill2008parscit}, as well as \citet{groza2012reference} rely on \glspl{crf} for extracting bibliographic information from research papers.
The three approaches followed the same steps:
After extracting and segmenting the reference strings, they are split into tokens and each token gets assigned a number of features.
Example for such features are the position in the line, whether or not the token starts with a capitalized letter, contains a dot, or only contains digits.
In addition, external lexicons are used in order to determine features like (author) surnames, places, and months.
The \gls{crf} is learned on data set containing between 200 and 830 references where every element of the reference gets analyzed for the set of features and also manually assigned a label such as author, title, year, and publisher.
The trained \gls{crf} is then used for labeling unseen testing data and the performance is evaluated using precision, recall, and the $\text{F}_1$ score.
\citet{groza2012reference} give an overview of the results of the three mentioned studies on the so-called CORA dataset which contains 200 reference strings.
The results show a very promising performance with $\text{F}_1$ scores higher than 93\% for all labeled element types and with an average of 96.7\% \citep{groza2012reference}.

Regarding the extraction of the reference string from a given research paper, \citet{councill2008parscit} as well as \citet{groza2012reference} relied on regular expressions that search for section labels like ``References'' or ``Bibliography'' and regarded the following text as reference strings.
Other regular expressions were used to identify a section heading that ends the reference  block such as ``Appendix'', ``Acknowledgments'', or the end of the document.
The content of the extracted reference block was separated into reference strings with another set of regular expressions that search for makers like ``[1]'', ``[PM04]'', or ``1.'' at the beginning of the lines.
If such markers were not found, other heuristics like author names at the beginning of the line, punctuation at the end of the line, and the length of the line were used.
This approach was sufficient for the considered use cases in computer science and health sciences \citep{councill2008parscit,groza2012reference}.
\citet{peng2004accurate} did not retrieve reference strings from research papers.\\

In summary, several aspects of the information extraction from research papers can be achieved with a considerably good performance.
In particular the segmentation of a given reference string into it's elements by using \glspl{crf} \citep{peng2004accurate,councill2008parscit,groza2012reference} as well as the combination of citation extraction and citation-reference matching \citep{powley2007evidence} show very promising results.
Yet, the extraction of reference strings from research papers is currently done with regular expressions that search for a section in the document that is labeled ``References'', ``Bibliography'', or similar.
In the case of research papers where the reference strings are listed in the footnotes on the page where they are referenced to, this approach is not suitable.
Instead of creating another set of regular expressions, we will discuss in the following chapters how \glspl{crf} can be used to correctly label strings in a paper as reference strings.
