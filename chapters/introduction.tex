\chapter{Introduction}\label{cha:introduction}

% What is the thesis about?
% Why is it relevant or important?
% What are the issues or problems?
% What is the proposed solution or approach?
% What can one expect in the rest of the thesis?

Citation data provides information on which scholarly work cites with other scholarly work.
This information is essential for the knowledge discovery process when conducting research and there are several services available that provide citation data for research areas like mathematics and physics\footnote{\url{http://related-work.net/}}, computer science\footnote{\url{http://dblp.uni-trier.de/}}, and medicine\footnote{\url{http://www.ncbi.nlm.nih.gov/pubmed}}.
Despite its importance, there is a shortage of citation data for German social science research papers~\citep{herb2015open}.
Even though there are commercial services available which provide citation data for a broad range of research areas, they do not provide a sufficient coverage of smaller academic fields like the German social sciences~\citep{mayr2007exploratory}.
In addition, commercial services generally do not publicly share their dataset which hinders a full utilization of the citation data.
The Social Science Citation Index\footnote{\url{http://scientific.thomson.com/products/ssci/}} by Thomson Reuters in particular was criticized for being ideologically biased and containing methodological deficiencies in the citation counting~\cite{klein2004social}.
Thereby, the motivation of this thesis is to contribute to the effort of extracting citation data from given research papers in order fill the gap regarding the German social sciences and to be less dependent on commercial services.

\bigskip

The general steps for extracting a citation network from research papers given in the \gls{pdf} format are shown in \Cref{fig:extraction-pipeline}.
\begin{figure}[t]
\includegraphics[width=\textwidth]{figures/extraction-pipeline}
\caption{Extraction pipeline for generating a citation network from given research papers in the \gls{pdf} format.}
\label{fig:extraction-pipeline}
\end{figure}
At first, the content of the \gls{pdf} files is converted to text files with an appropriate encoding to allow easier processing.
In the second step, the reference strings are extracted from the text.
The strings are then segmented into the different attributes that identify the referenced paper (step three).
Such attributes can be the authors, title, journal, and publication year.
Step four is to match this information against existing meta data records in order to assign a unique identifier such as a \textit{digital object identifier} (DOI).
This results in a citation network between unique authors.

It is not the goal of this thesis to cover the whole pipeline.
Instead, we focus on the extraction of author names from the reference section of a given research paper.
The goal is to develop an approach that is able to distinguish between individual authors in a reference string as well as their first names and last names.
Further, we focus on the extraction from research papers in the area of German social sciences.

\bigskip

Since there is no data set available to address the given problem with a supervised machine learning approach, we will look into the concept of distant supervision.
This allows an automated tagging of unlabeled data using an external knowledge base.
In our scenario, this knowledge base is a list of author names from related research domains.
To apply an automated tagging of author names in reference strings, several issues need to be addressed.
For example, there are several ways in which an author name can be written in a reference string.
An automated tagging also often results in overlapping tags when multiple authors are listed in one reference string.
Instead of considering only one of the overlapping tags, we want to include all available information in our model.
For this, we will discuss the \gls{goddag} as an appropriate data structure for representing overlapping tags.

The probabilistic framework of \glspl{crf} is widely used for entity recognition tasks.
Yet, their original definition by \citet{lafferty2001conditional} is only applicable on fully labeled training data whereas distant supervision provides partially labeled data.
We will discuss two different approaches that allow the usage of distantly supervised training sets for the learning of \glspl{crf}:
The first one is a marginalization approach by \citet{tsuboi2008training}.
The second approach uses \gls{ge} constraints that were first proposed by \citet{mann2007simple}.
We will show that the marginalization approach is less suitable for a distantly supervised training than \gls{ge} constraints.
As a result, our author extraction implementation uses \gls{ge} constraints to learn \glspl{crf}.
This combination of distant supervision with \gls{ge} constraints for learning \glspl{crf} was first applied by \citet{lu2013web} in the context of web entity detection.

\bigskip

The remainder of this thesis is structured as follows.
In \Cref{cha:related-work}, we give an overview of the related work in the area of entity recognition with a focus on reference string extraction.
Using the author extraction problem as an example, \Cref{cha:crfs} discussed the foundations of \glspl{crf} as well as their encoding, inferencing, and learning.
\Cref{cha:distant-supervision} focuses on distant supervision as an approach to learn \glspl{crf} by comparing the approaches of marginalization and \gls{ge} constraints.
The different steps of our author extraction approach are discussed in more detail in \Cref{cha:author-extraction}.
In this chapter, we also state the research questions that we address in this thesis.
Following this, we present our author extraction implementation in \Cref{cha:implementation}.
This will be used in \Cref{cha:evaluation} to construct an evaluation that is based on our research questions.
In \Cref{cha:conclusion-and-future-work}, we conclude the thesis and discuss the possible future work.

